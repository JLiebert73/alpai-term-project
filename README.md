# Training MAML with RK-2&4 in Pytorch ðŸš€
**
# Group Project by: Nisarg Bhavsar, Akash Kaushik, Vedic Dutta, Ashesh Xalxo

Meta-learning has become crucial for developing models that can quickly adapt to new tasks with limited data. The Model-Agnostic Meta-Learning (MAML) framework stands out for its efficiency in fine-tuning models across diverse tasks. This report extends the traditional MAML framework by incorporating fourth-order Runge-Kutta (RK4) methods, aiming to enhance optimization beyond the capabilities of the previously used second-order methods.

Our experiments replicated the original setups from recent studies that applied second-order Runge-Kutta (RK2) methods to MAML. By integrating RK4, we observed a significant increase in one-shot classification accuracy, highlighting the potential of higher-order numerical methods in optimizing meta-learning processes. This work demonstrates the feasibility of using RK4 to boost MAMLâ€™s performance and sets the stage for further explorations into sophisticated numerical integration techniques within meta-learning.


**
